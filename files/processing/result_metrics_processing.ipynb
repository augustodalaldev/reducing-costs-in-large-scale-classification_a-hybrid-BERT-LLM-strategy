{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a97b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "path_results = \"./mpnet_base_v2_metrics_emissions/tables/\"\n",
    "model_name = \"mpnet_base_v2\"\n",
    "path_model = \"./mpnet_base_v2_metrics_emissions/parts/\"\n",
    "arquivos = glob.glob(f\"{path_model}*.parquet\")\n",
    "\n",
    "df_result_metricas = pd.read_parquet(arquivos[0])\n",
    "for i, e in enumerate(arquivos):\n",
    "    if i == 0:\n",
    "        continue\n",
    "\n",
    "    df_result_metricas = pd.concat([df_result_metricas, pd.read_parquet(arquivos[i])], ignore_index=True)\n",
    "\n",
    "\n",
    "df_result_metricas = df_result_metricas.sort_values(by=[\"tema\", \"threshold\", \"agg_chunk\", \"agg_campos\", \"agg_sim_tema_palavras\"])\n",
    "\n",
    "df_result_metricas = df_result_metricas.reset_index(drop=True)\n",
    "df_result_metricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef817293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_metricas.to_csv(f\"{path_results}{model_name}_result_all_metrics_by_agg.csv\", index=False)\n",
    "df_result_metricas.to_parquet(f\"{path_results}{model_name}_result_all_metrics_by_agg.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b20d9e",
   "metadata": {},
   "source": [
    "Criação da Tabela De Top F1's Macro por métodos de agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ac0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_agg_types = df_result_metricas[\"agg_chunk\"].unique()\n",
    "chunk_agg_types.sort()\n",
    "\n",
    "campos_agg_types = df_result_metricas[\"agg_campos\"].unique()\n",
    "campos_agg_types.sort()\n",
    "\n",
    "sim_tema_palavras_agg_types = df_result_metricas[\"agg_sim_tema_palavras\"].unique()\n",
    "sim_tema_palavras_agg_types.sort()\n",
    "\n",
    "dict_top_f1 = {}\n",
    "\n",
    "for a in chunk_agg_types:\n",
    "    for b in campos_agg_types:\n",
    "        # chave do índice da linha\n",
    "        dict_top_f1[(a, b)] = {}\n",
    "        for e in sim_tema_palavras_agg_types:\n",
    "            df_filtered = df_result_metricas[\n",
    "                (df_result_metricas[\"agg_chunk\"] == a) &\n",
    "                (df_result_metricas[\"agg_campos\"] == b) &\n",
    "                (df_result_metricas[\"agg_sim_tema_palavras\"] == e)\n",
    "            ]\n",
    "            \n",
    "            \n",
    "            # Agrupa por threshold e calcula média e desvio padrão\n",
    "            stats_f1_per_threshold = df_filtered.groupby(\"threshold\")[\"macro_avg_f1_score\"].agg([\"mean\", \"std\"])\n",
    "\n",
    "            # Melhor threshold baseado na média, e então melhor macro e melhor desvio padrao associado\n",
    "            best_threshold = stats_f1_per_threshold[\"mean\"].idxmax()\n",
    "            best_mean_f1 = stats_f1_per_threshold.loc[best_threshold, \"mean\"]\n",
    "            best_std  = stats_f1_per_threshold.loc[best_threshold, \"std\"]\n",
    "\n",
    "            # cada coluna do MultiIndex\n",
    "            dict_top_f1[(a, b)][(e, \"threshold\")] = best_threshold \n",
    "            dict_top_f1[(a, b)][(e, \"f1_macro_mean\")] = best_mean_f1\n",
    "            dict_top_f1[(a, b)][(e, \"f1_macro_std\")] = best_std\n",
    "\n",
    "# Agora criamos o DataFrame\n",
    "df_top_f1 = pd.DataFrame.from_dict(dict_top_f1, orient=\"index\")\n",
    "\n",
    "# Definindo MultiIndex nas linhas\n",
    "df_top_f1.index = pd.MultiIndex.from_tuples(df_top_f1.index, names=[\"chunk_agg_tipo\", \"sources_agg_tipo\"])\n",
    "\n",
    "# Definindo MultiIndex nas colunas\n",
    "df_top_f1.columns = pd.MultiIndex.from_tuples(df_top_f1.columns, names=[\"sim_tema_palavras_agg_tipo\", \"metric\"])\n",
    "\n",
    "df_top_f1 = df_top_f1.sort_index(axis=1)\n",
    "\n",
    "df_top_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4af125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1.to_csv(f\"{path_results}{model_name}_top_f1.csv\")\n",
    "df_top_f1.to_parquet(f\"{path_results}{model_name}_top_f1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431eb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metrics(df: pd.DataFrame, metrics_to_keep=None, metrics_to_drop=None):\n",
    "    \"\"\"\n",
    "    Filtra colunas de um DataFrame com MultiIndex de colunas,\n",
    "    baseado nos valores do nível \"metric\".\n",
    "\n",
    "    - metrics_to_keep: lista de métricas que você quer manter\n",
    "    - metrics_to_drop: lista de métricas que você quer remover\n",
    "\n",
    "    Retorna um novo DataFrame filtrado.\n",
    "    \"\"\"\n",
    "    cols_metric = df.columns.get_level_values(\"metric\")\n",
    "\n",
    "    if metrics_to_keep is not None:\n",
    "        mask = cols_metric.isin(metrics_to_keep)\n",
    "    elif metrics_to_drop is not None:\n",
    "        mask = ~cols_metric.isin(metrics_to_drop)\n",
    "    else:\n",
    "        # Se nada for passado, mantém tudo\n",
    "        mask = [True] * len(df.columns)\n",
    "\n",
    "    return df.loc[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_no_threshold = filter_metrics(df_top_f1, [\"f1_macro_mean\", \"f1_macro_std\"], [\"threhshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_no_threshold.to_csv(f\"{path_results}{model_name}_top_f1_no_threshold.csv\")\n",
    "df_top_f1_no_threshold.to_parquet(f\"{path_results}{model_name}_top_f1_no_threshold.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_only_f1 = filter_metrics(df_top_f1_no_threshold, [\"f1_macro_mean\"], [\"f1_macro_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a87f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_only_f1.to_csv(f\"{path_results}{model_name}_top_f1_only_f1.csv\")\n",
    "df_top_f1_only_f1.to_parquet(f\"{path_results}{model_name}_top_f1_only_f1.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d68f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_only_std = filter_metrics(df_top_f1_no_threshold, [\"f1_macro_std\"], [\"f1_macro_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf8a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_only_std.to_parquet(f\"{path_results}{model_name}_top_f1_only_std.parquet\")\n",
    "df_top_f1_only_std.to_csv(f\"{path_results}{model_name}_top_f1_only_std.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5578cbfc",
   "metadata": {},
   "source": [
    "Tabela F1_ALTO médio e Recall_ALTO médio associado ao threshold F1 Macro Medio máximo por cenário de agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22719851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_agg_types = df_result_metricas[\"agg_chunk\"].unique()\n",
    "chunk_agg_types.sort()\n",
    "\n",
    "campos_agg_types = df_result_metricas[\"agg_campos\"].unique()\n",
    "campos_agg_types.sort()\n",
    "\n",
    "sim_tema_palavras_agg_types = df_result_metricas[\"agg_sim_tema_palavras\"].unique()\n",
    "sim_tema_palavras_agg_types.sort()\n",
    "\n",
    "dict_top_f1_ALTO_metrics = {}\n",
    "\n",
    "for a in chunk_agg_types:\n",
    "    for b in campos_agg_types:\n",
    "        # chave do índice da linha\n",
    "        dict_top_f1_ALTO_metrics[(a, b)] = {}\n",
    "        for e in sim_tema_palavras_agg_types:\n",
    "            df_filtered = df_result_metricas[\n",
    "                (df_result_metricas[\"agg_chunk\"] == a) &\n",
    "                (df_result_metricas[\"agg_campos\"] == b) &\n",
    "                (df_result_metricas[\"agg_sim_tema_palavras\"] == e)\n",
    "            ]\n",
    "            \n",
    "            \n",
    "            stats_per_threshold = df_filtered.groupby(\"threshold\").agg({\n",
    "                \"macro_avg_f1_score\": [\"mean\", \"std\"],\n",
    "                \"ALTO_f1_score\": \"mean\",\n",
    "                \"ALTO_recall\": \"mean\"   # <-- adiciona recall médio também\n",
    "            })\n",
    "\n",
    "            # Ajusta MultiIndex das colunas\n",
    "            stats_per_threshold.columns = [\"f1_macro_mean\",\"f1_macro_std\", \"f1_ALTO_mean_assoc\", \"recall_ALTO_mean_assoc\"]\n",
    "\n",
    "            # Melhor threshold pelo F1 médio\n",
    "            best_threshold = stats_per_threshold[\"f1_macro_mean\"].idxmax()\n",
    "            best_mean_f1   = stats_per_threshold.loc[best_threshold, \"f1_macro_mean\"]\n",
    "            best_std       = stats_per_threshold.loc[best_threshold, \"f1_macro_std\"]\n",
    "\n",
    "            #f1 ALTO e recall ALTO associados ao f1 médio máximo\n",
    "            best_f1_ALTO    = stats_per_threshold.loc[best_threshold, \"f1_ALTO_mean_assoc\"]\n",
    "            best_recall_ALTO    = stats_per_threshold.loc[best_threshold, \"recall_ALTO_mean_assoc\"]\n",
    "\n",
    "            # Salvar no dict\n",
    "            dict_top_f1_ALTO_metrics[(a, b)][(e, \"threshold\")]      = best_threshold\n",
    "            dict_top_f1_ALTO_metrics[(a, b)][(e, \"f1_macro_mean\")]  = best_mean_f1\n",
    "            dict_top_f1_ALTO_metrics[(a, b)][(e, \"f1_macro_std\")]   = best_std\n",
    "            dict_top_f1_ALTO_metrics[(a, b)][(e, \"f1_ALTO_mean_assoc\")]  = best_f1_ALTO\n",
    "            dict_top_f1_ALTO_metrics[(a, b)][(e, \"recall_ALTO_mean_assoc\")]  = best_recall_ALTO\n",
    "\n",
    "# Agora criamos o DataFrame\n",
    "df_top_f1_ALTO_metrics = pd.DataFrame.from_dict(dict_top_f1_ALTO_metrics, orient=\"index\")\n",
    "\n",
    "# Definindo MultiIndex nas linhas\n",
    "df_top_f1_ALTO_metrics.index = pd.MultiIndex.from_tuples(df_top_f1_ALTO_metrics.index, names=[\"chunk_agg_tipo\", \"sources_agg_tipo\"])\n",
    "\n",
    "# Definindo MultiIndex nas colunas\n",
    "df_top_f1_ALTO_metrics.columns = pd.MultiIndex.from_tuples(df_top_f1_ALTO_metrics.columns, names=[\"sim_tema_palavras_agg_tipo\", \"metric\"])\n",
    "\n",
    "\n",
    "df_top_f1_ALTO_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_ALTO_metrics.to_csv(f\"{path_results}{model_name}_top_f1_ALTO_metrics.csv\")\n",
    "df_top_f1_ALTO_metrics.to_parquet(f\"{path_results}{model_name}_top_f1_ALTO_metrics.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6480142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_ALTO_metrics_only_f1_ALTO = filter_metrics(df_top_f1_ALTO_metrics, [\"f1_ALTO_mean_assoc\"], None)\n",
    "df_top_f1_ALTO_metrics_only_f1_ALTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9055337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_ALTO_metrics_only_f1_ALTO.to_csv(f\"{path_results}{model_name}_top_f1_ALTO_metrics_only_f1_ALTO.csv\")\n",
    "df_top_f1_ALTO_metrics_only_f1_ALTO.to_parquet(f\"{path_results}{model_name}_top_f1_ALTO_metrics_only_f1_ALTO.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc158330",
   "metadata": {},
   "source": [
    "Tabela F1_NAO-ALTO médio e Recall_NAO-ALTO médio associado ao threshold F1 Macro Medio máximo por cenário de agregação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf550df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "chunk_agg_types = df_result_metricas[\"agg_chunk\"].unique()\n",
    "chunk_agg_types.sort()\n",
    "\n",
    "campos_agg_types = df_result_metricas[\"agg_campos\"].unique()\n",
    "campos_agg_types.sort()\n",
    "\n",
    "sim_tema_palavras_agg_types = df_result_metricas[\"agg_sim_tema_palavras\"].unique()\n",
    "sim_tema_palavras_agg_types.sort()\n",
    "\n",
    "dict_top_f1_NAO_ALTO_metrics = {}\n",
    "\n",
    "for a in chunk_agg_types:\n",
    "    for b in campos_agg_types:\n",
    "        dict_top_f1_NAO_ALTO_metrics[(a, b)] = {}\n",
    "        for e in sim_tema_palavras_agg_types:\n",
    "            df_filtered = df_result_metricas[\n",
    "                (df_result_metricas[\"agg_chunk\"] == a) &\n",
    "                (df_result_metricas[\"agg_campos\"] == b) &\n",
    "                (df_result_metricas[\"agg_sim_tema_palavras\"] == e)\n",
    "            ]\n",
    "            \n",
    "            stats_per_threshold = df_filtered.groupby(\"threshold\").agg({\n",
    "                \"macro_avg_f1_score\": [\"mean\", \"std\"],\n",
    "                \"NAO-ALTO_f1_score\": \"mean\",\n",
    "                \"NAO-ALTO_recall\": \"mean\"\n",
    "            })\n",
    "\n",
    "            stats_per_threshold.columns = [\n",
    "                \"f1_macro_mean\", \"f1_macro_std\",\n",
    "                \"f1_NAO_ALTO_mean_assoc\", \"recall_NAO_ALTO_mean_assoc\"\n",
    "            ]\n",
    "\n",
    "            # Melhor threshold pelo F1 macro\n",
    "            best_threshold = stats_per_threshold[\"f1_macro_mean\"].idxmax()\n",
    "            best_mean_f1   = stats_per_threshold.loc[best_threshold, \"f1_macro_mean\"]\n",
    "            best_std       = stats_per_threshold.loc[best_threshold, \"f1_macro_std\"]\n",
    "\n",
    "            # f1 e recall NAO-ALTO associados ao f1 macro máximo\n",
    "            best_f1_NAO_ALTO    = stats_per_threshold.loc[best_threshold, \"f1_NAO_ALTO_mean_assoc\"]\n",
    "            best_recall_NAO_ALTO = stats_per_threshold.loc[best_threshold, \"recall_NAO_ALTO_mean_assoc\"]\n",
    "\n",
    "            # Salvar no dict\n",
    "            dict_top_f1_NAO_ALTO_metrics[(a, b)][(e, \"threshold\")] = best_threshold\n",
    "            dict_top_f1_NAO_ALTO_metrics[(a, b)][(e, \"f1_macro_mean\")] = best_mean_f1\n",
    "            dict_top_f1_NAO_ALTO_metrics[(a, b)][(e, \"f1_macro_std\")] = best_std\n",
    "            dict_top_f1_NAO_ALTO_metrics[(a, b)][(e, \"f1_NAO_ALTO_mean_assoc\")] = best_f1_NAO_ALTO\n",
    "            dict_top_f1_NAO_ALTO_metrics[(a, b)][(e, \"recall_NAO_ALTO_mean_assoc\")] = best_recall_NAO_ALTO\n",
    "\n",
    "# Criar DataFrame\n",
    "df_top_f1_NAO_ALTO_metrics = pd.DataFrame.from_dict(dict_top_f1_NAO_ALTO_metrics, orient=\"index\")\n",
    "\n",
    "# Definir MultiIndex nas linhas\n",
    "df_top_f1_NAO_ALTO_metrics.index = pd.MultiIndex.from_tuples(\n",
    "    df_top_f1_NAO_ALTO_metrics.index, names=[\"chunk_agg_tipo\", \"sources_agg_tipo\"]\n",
    ")\n",
    "\n",
    "# Definir MultiIndex nas colunas\n",
    "df_top_f1_NAO_ALTO_metrics.columns = pd.MultiIndex.from_tuples(\n",
    "    df_top_f1_NAO_ALTO_metrics.columns, names=[\"sim_tema_palavras_agg_tipo\", \"metric\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942fa778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_NAO_ALTO_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_top_f1_NAO_ALTO_metrics.to_csv(f\"{path_results}{model_name}_top_f1_NAO_ALTO_metrics.csv\")\n",
    "df_top_f1_NAO_ALTO_metrics.to_parquet(f\"{path_results}{model_name}_top_f1_NAO_ALTO_metrics.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad80a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apenas f1_NAO_ALTO\n",
    "df_top_f1_NAO_ALTO_metrics_only_f1_NAO_ALTO = filter_metrics(\n",
    "    df_top_f1_NAO_ALTO_metrics, metrics_to_keep=[\"f1_NAO_ALTO_mean_assoc\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a1fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_f1_NAO_ALTO_metrics_only_f1_NAO_ALTO.to_csv(f\"{path_results}{model_name}_top_f1_NAO_ALTO_metrics_only_f1_NAO_ALTO.csv\")\n",
    "df_top_f1_NAO_ALTO_metrics_only_f1_NAO_ALTO.to_parquet(f\"{path_results}{model_name}_top_f1_NAO_ALTO_metrics_only_f1_NAO_ALTO.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Pegamos só as colunas de f1_macro\n",
    "df_f1 = df_top_f1.xs(\"f1_macro_mean\", level=\"metric\", axis=1)\n",
    "\n",
    "# 2. Valor máximo\n",
    "max_value = df_f1.to_numpy().max()\n",
    "\n",
    "# 3. Posição (linha e coluna)\n",
    "row, col = np.where(df_f1.to_numpy() == max_value)\n",
    "row = row[0]\n",
    "col = col[0]\n",
    "\n",
    "# 4. Recuperar índice e coluna\n",
    "row_index = df_f1.index[row]          # (chunk_agg_tipo, sources_agg_tipo)\n",
    "col_index = df_f1.columns[col]        # sim_tema_palavras_agg_tipo\n",
    "\n",
    "# 5. Recuperar o threshold correspondente\n",
    "threshold_value = df_top_f1.loc[row_index, (col_index, \"threshold\")]\n",
    "\n",
    "print(\"Maior f1_macro:\", max_value)\n",
    "print(\"Linha (chunk_agg_tipo, sources_agg_tipo):\", row_index)\n",
    "print(\"Coluna (sim_tema_palavras_agg_tipo):\", col_index)\n",
    "print(\"Threshold correspondente:\", threshold_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4cabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "df_filtered = df_result_metricas[\n",
    "    (df_result_metricas[\"agg_chunk\"] == row_index[0]) &\n",
    "    (df_result_metricas[\"agg_campos\"] == row_index[1]) &\n",
    "    (df_result_metricas[\"agg_sim_tema_palavras\"] == col_index)\n",
    "]\n",
    "\n",
    "histograma = df_filtered[df_filtered[\"threshold\"] == threshold_value].macro_avg_f1_score.hist()\n",
    "\n",
    "\n",
    "histograma.set\n",
    "histograma.set_xlabel('f1_macro_mean')\n",
    "histograma.set_ylabel('frequency')\n",
    "\n",
    "plt.savefig(f\"{path_results}{model_name}_hist__agg_chunk_{row_index[0]}__agg_campos_{row_index[1]}__agg_sim_temas_palavras_{col_index}__threshold_{int(threshold_value*100)}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "histograma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LeanDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
